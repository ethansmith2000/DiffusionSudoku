{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sudoku_mrv import generate_board, verify_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = generate_board(completeness=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 4, 3, 9, 1, 6, 7, 2, 5],\n",
       " [6, 9, 2, 5, 7, 8, 3, 4, 1],\n",
       " [7, 1, 5, 4, 2, 3, 6, 8, 9],\n",
       " [2, 3, 4, 6, 5, 9, 8, 1, 7],\n",
       " [9, 7, 6, 1, 8, 4, 5, 3, 2],\n",
       " [1, 5, 8, 2, 3, 7, 4, 9, 6],\n",
       " [3, 2, 7, 8, 9, 5, 1, 6, 4],\n",
       " [4, 8, 9, 7, 6, 1, 2, 5, 3],\n",
       " [5, 6, 1, 3, 4, 2, 9, 7, 8]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_board(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import math \n",
    "# sampling helpers\n",
    "\n",
    "def log(t, eps = 1e-20):\n",
    "    return torch.log(t.clamp(min = eps))\n",
    "\n",
    "def gumbel_noise(t):\n",
    "    noise = torch.zeros_like(t).uniform_(0, 1)\n",
    "    return -log(-log(noise))\n",
    "\n",
    "def gumbel_sample(t, temperature = 1., dim = -1):\n",
    "    return ((t / max(temperature, 1e-10)) + gumbel_noise(t)).argmax(dim = dim)\n",
    "\n",
    "def top_k(logits, thres = 0.9):\n",
    "    k = math.ceil((1 - thres) * logits.shape[-1])\n",
    "    val, ind = logits.topk(k, dim = -1)\n",
    "    probs = torch.full_like(logits, float('-inf'))\n",
    "    probs.scatter_(2, ind, val)\n",
    "    return probs\n",
    "\n",
    "# noise schedules\n",
    "\n",
    "def cosine_schedule(t):\n",
    "    return torch.cos(t * math.pi * 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from PIL import Image\n",
    "import io\n",
    "from matplotlib import gridspec\n",
    "\n",
    "def visualize_sudoku(board, title=None, cmap=None, show_values=True, figsize=(6, 6)):\n",
    "    \"\"\"\n",
    "    Visualize a Sudoku board with different colors for each number.\n",
    "    \n",
    "    Args:\n",
    "        board: A 9x9 numpy array or list of lists representing the Sudoku board\n",
    "        title: Optional title for the plot\n",
    "        cmap: Optional custom colormap (default is a pastel colormap)\n",
    "        show_values: Whether to display the numerical values in cells\n",
    "        figsize: Size of the figure (width, height) in inches\n",
    "        \n",
    "    Returns:\n",
    "        A PIL Image of the visualization\n",
    "    \"\"\"\n",
    "    # Create a new figure for each board to prevent any sharing\n",
    "    plt.clf()  # Clear the current figure\n",
    "    plt.close('all')  # Close all figures\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "    # Convert to numpy array if it's a list\n",
    "    if isinstance(board, list):\n",
    "        board = np.array(board)\n",
    "    \n",
    "    # Create a default colormap if none provided\n",
    "    if cmap is None:\n",
    "        # Create a colormap with 10 colors (0-9, where 0 is empty)\n",
    "        colors = ['#FFFFFF',  # 0: White (empty)\n",
    "                 '#FFB3BA',  # 1: Light pink\n",
    "                 '#FFDFBA',  # 2: Light orange\n",
    "                 '#FFFFBA',  # 3: Light yellow\n",
    "                 '#BAFFC9',  # 4: Light green\n",
    "                 '#BAE1FF',  # 5: Light blue\n",
    "                 '#D0BAFF',  # 6: Light purple\n",
    "                 '#FFB3F6',  # 7: Light magenta\n",
    "                 '#C4C4C4',  # 8: Light gray\n",
    "                 '#FFD700']  # 9: Gold - changed from light cyan\n",
    "        cmap = ListedColormap(colors)\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Plot the board\n",
    "    im = ax.imshow(board, cmap=cmap, vmin=0, vmax=9)\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(10):\n",
    "        lw = 2 if i % 3 == 0 else 0.5\n",
    "        ax.axhline(i - 0.5, color='black', linewidth=lw)\n",
    "        ax.axvline(i - 0.5, color='black', linewidth=lw)\n",
    "    \n",
    "    # Add values to cells if requested\n",
    "    if show_values:\n",
    "        for i in range(9):\n",
    "            for j in range(9):\n",
    "                if board[i, j] != 0:\n",
    "                    ax.text(j, i, str(board[i, j]), ha='center', va='center', \n",
    "                            fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Remove ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Add title if provided\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Convert to PIL image\n",
    "    pil_image = fig_to_pil(fig)\n",
    "    plt.close(fig)  # Close the figure to avoid displaying it\n",
    "    return pil_image\n",
    "\n",
    "def fig_to_pil(fig):\n",
    "    \"\"\"Convert a matplotlib figure to a PIL Image\"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mult=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mult * 2), nn.GELU(), nn.Linear(dim * mult * 2, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, heads=8):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=self.heads), self.to_qkv(x).chunk(3, dim=-1))\n",
    "        attn_out = torch.nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "        out = rearrange(attn_out, \"b h n d -> b n (h d)\", h=self.heads)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, head_dim, heads=8):\n",
    "        super().__init__()\n",
    "        dim = head_dim * heads\n",
    "        self.attn = Attention(dim, heads)\n",
    "        self.ff = FeedForward(dim)\n",
    "        self.attn_norm = nn.LayerNorm(dim)\n",
    "        self.ff_norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.attn_norm(x))\n",
    "        x = x + self.ff(self.ff_norm(x))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, head_dim=64, heads=8, num_classes=10, depth=12, ff_mult=4, dropout=0.0):\n",
    "        super().__init__()\n",
    "        dim = head_dim * heads\n",
    "        self.embed = nn.Embedding(num_classes, dim)\n",
    "        self.pos_emb = nn.Embedding(81, dim)\n",
    "        self.layers = nn.ModuleList([TransformerBlock(head_dim, heads) for _ in range(depth)])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.to_logits = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        pos_idx = torch.arange(x.shape[1], device=x.device)\n",
    "        pos_embs = self.pos_emb(pos_idx)\n",
    "        x = x + pos_embs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        return self.to_logits(x)\n",
    "\n",
    "\n",
    "class DiscreteDiffusion(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, head_dim=64, heads=8, depth=12, ff_mult=4, dropout=0.0, no_mask_token_prob=0.0, full_mask_token_prob=0.025):\n",
    "        super().__init__()\n",
    "        self.model = Transformer(head_dim, heads, num_classes, depth, ff_mult, dropout)\n",
    "        self.no_mask_token_prob = no_mask_token_prob\n",
    "        self.full_mask_token_prob = full_mask_token_prob\n",
    "\n",
    "    def forward(self, board_bl, labels=None):\n",
    "        \"\"\"\n",
    "        forward and compute loss\n",
    "        \"\"\"\n",
    "        preds_bld = self.model(board_bl)\n",
    "        if labels is not None:\n",
    "            loss = nn.functional.cross_entropy(preds_bld.reshape(-1, preds_bld.shape[-1]), labels.flatten(0), ignore_index=-1)\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        return preds_bld, loss\n",
    "\n",
    "    def forward_loss(self, board_bhw, ignore_index=-1):\n",
    "        mask_id = 0\n",
    "        b, h, w = board_bhw.shape\n",
    "        board_bl = board_bhw.flatten(1)\n",
    "        _, l = board_bl.shape\n",
    "\n",
    "        rand_time = torch.rand(board_bhw.shape[0], device=board_bl.device)\n",
    "        rand_mask_probs = cosine_schedule(rand_time)\n",
    "        num_token_masked = (l * rand_mask_probs).round().clamp(min = 1)\n",
    "\n",
    "        batch_randperm = torch.rand((b, l), device = board_bhw.device).argsort(dim = -1)\n",
    "        mask = batch_randperm < rearrange(num_token_masked, 'b -> b 1')\n",
    "\n",
    "        labels = torch.where(mask, board_bl, ignore_index)\n",
    "\n",
    "        if self.no_mask_token_prob > 0.:\n",
    "            no_mask_mask = get_mask_subset_prob(mask, self.no_mask_token_prob)\n",
    "            mask &= ~no_mask_mask\n",
    "        \n",
    "        if self.full_mask_token_prob > 0.:\n",
    "            full_mask_mask = torch.full_like(mask, True)\n",
    "            #bernouli\n",
    "            indices = torch.arange(b, device=mask.device)\n",
    "            indices_mask = torch.bernoulli(torch.full((b,), self.full_mask_token_prob, device=mask.device)).long()\n",
    "            indices = indices[indices_mask]\n",
    "            mask[indices] = full_mask_mask[indices]\n",
    "\n",
    "        board_bl = torch.where(mask, mask_id, board_bl)\n",
    "\n",
    "        preds_bld, loss = self.forward(board_bl, labels=labels)\n",
    "\n",
    "        return preds_bld, loss\n",
    "\n",
    "    def generate(self, batch_size=32, timesteps=128, temperature=1.0, topk_filter_thres = 0.9, can_remask_prev_masked = False,):\n",
    "        device = next(self.parameters()).device\n",
    "        shape = (batch_size, 9, 9)\n",
    "        board_bhw = torch.full(shape, 0, dtype=torch.long, device=device)\n",
    "        scores_bhw = torch.zeros(shape, dtype = torch.float32, device = device)\n",
    "        board_bl = board_bhw.flatten(1)\n",
    "        scores_bl = scores_bhw.flatten(1)\n",
    "        seq_len = board_bl.shape[1]\n",
    "\n",
    "        starting_temperature = temperature\n",
    "        mask_id = 0\n",
    "\n",
    "        for timestep, steps_until_x0 in tqdm(zip(torch.linspace(0, 1, timesteps, device = device), reversed(range(timesteps))), total = timesteps):\n",
    "            rand_mask_prob = cosine_schedule(timestep)\n",
    "            num_token_masked = max(int((rand_mask_prob * seq_len).item()), 1)\n",
    "\n",
    "            masked_indices = scores_bl.topk(num_token_masked, dim = -1).indices\n",
    "\n",
    "            board_bl = board_bl.scatter(1, masked_indices, mask_id)\n",
    "\n",
    "            logits, _ = self.forward(board_bl)\n",
    "\n",
    "            filtered_logits = top_k(logits, topk_filter_thres)\n",
    "\n",
    "            temperature = starting_temperature * (steps_until_x0 / timesteps) # temperature is annealed\n",
    "\n",
    "            pred_ids = gumbel_sample(filtered_logits, temperature = temperature, dim = -1)\n",
    "\n",
    "            is_mask = board_bl == mask_id\n",
    "\n",
    "            board_bl = torch.where(\n",
    "                is_mask,\n",
    "                pred_ids,\n",
    "                board_bl\n",
    "            )\n",
    "\n",
    "            probs_without_temperature = logits.softmax(dim = -1)\n",
    "\n",
    "            scores_bl = 1 - probs_without_temperature.gather(2, pred_ids[..., None])\n",
    "            scores_bl = rearrange(scores_bl, '... 1 -> ...')\n",
    "\n",
    "            if not can_remask_prev_masked:\n",
    "                scores_bl = scores_bl.masked_fill(~is_mask, -1e5)\n",
    "            else:\n",
    "                assert self.no_mask_token_prob > 0., 'without training with some of the non-masked tokens forced to predict, not sure if the logits will be meaningful for these token'\n",
    "\n",
    "        board_bhw = board_bl.reshape(board_bhw.shape)\n",
    "\n",
    "        return board_bhw\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 117.46it/s]13.75it/s, loss=2.22, lr=1e-5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.92it/s] 13.75it/s, loss=2.21, lr=2e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.77it/s] 13.66it/s, loss=2.2, lr=3e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 313/313 [00:35<00:00,  8.90it/s, loss=2.19, lr=3.13e-5]\n",
      "100%|██████████| 128/128 [00:01<00:00, 125.96it/s]13.78it/s, loss=2.19, lr=4e-5]   \n",
      "Epoch 2/10:  28%|██▊       | 87/313 [00:11<02:24,  1.57it/s, loss=2.19, lr=4e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 126.15it/s] 13.77it/s, loss=2.18, lr=5e-5]   \n",
      "Epoch 2/10:  60%|█████▉    | 187/313 [00:21<01:13,  1.73it/s, loss=2.18, lr=5e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 126.11it/s] 13.75it/s, loss=2.18, lr=6e-5]   \n",
      "Epoch 2/10:  92%|█████████▏| 287/313 [00:32<00:16,  1.61it/s, loss=2.18, lr=6e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 313/313 [00:34<00:00,  8.99it/s, loss=2.17, lr=6.26e-5]\n",
      "100%|██████████| 128/128 [00:01<00:00, 125.93it/s]13.74it/s, loss=2.15, lr=7e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.67it/s] 13.78it/s, loss=1.9, lr=8e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.88it/s] 13.79it/s, loss=1.71, lr=9e-5]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 313/313 [00:34<00:00,  9.04it/s, loss=1.72, lr=9.39e-5]\n",
      "100%|██████████| 128/128 [00:01<00:00, 126.01it/s]13.77it/s, loss=1.63, lr=0.0001] \n",
      "Epoch 4/10:  19%|█▉        | 61/313 [00:08<02:30,  1.68it/s, loss=1.63, lr=0.0001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.70it/s] 13.75it/s, loss=1.56, lr=9.53e-5]\n",
      "Epoch 4/10:  51%|█████▏    | 161/313 [00:20<01:41,  1.50it/s, loss=1.56, lr=9.53e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.99it/s] 13.80it/s, loss=1.75, lr=9.06e-5]\n",
      "Epoch 4/10:  83%|████████▎ | 261/313 [00:30<00:30,  1.72it/s, loss=1.75, lr=9.06e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 313/313 [00:34<00:00,  9.00it/s, loss=1.75, lr=8.82e-5]\n",
      "100%|██████████| 128/128 [00:01<00:00, 125.87it/s]13.75it/s, loss=1.35, lr=8.59e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.93it/s] 13.77it/s, loss=1.41, lr=8.12e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.80it/s] 13.76it/s, loss=1.5, lr=7.65e-5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 313/313 [00:34<00:00,  8.99it/s, loss=1.6, lr=7.35e-5] \n",
      "100%|██████████| 128/128 [00:01<00:00, 125.83it/s]13.69it/s, loss=1.66, lr=7.18e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.92it/s] 13.77it/s, loss=1.65, lr=6.71e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.85it/s] 13.72it/s, loss=1.53, lr=6.24e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 313/313 [00:34<00:00,  8.96it/s, loss=1.76, lr=5.88e-5]\n",
      "100%|██████████| 128/128 [00:01<00:00, 125.91it/s]12.78it/s, loss=1.48, lr=5.77e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.80it/s] 13.76it/s, loss=1.64, lr=5.31e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.88it/s] 13.72it/s, loss=1.69, lr=4.84e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 313/313 [00:34<00:00,  9.07it/s, loss=1.48, lr=4.41e-5]\n",
      "100%|██████████| 128/128 [00:01<00:00, 125.92it/s]6.71it/s, loss=1.59, lr=4.37e-5]\n",
      "Epoch 8/10:   3%|▎         | 9/313 [00:05<03:56,  1.28it/s, loss=1.59, lr=4.37e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 126.02it/s] 13.75it/s, loss=1.38, lr=3.9e-5] \n",
      "Epoch 8/10:  35%|███▍      | 109/313 [00:16<02:31,  1.35it/s, loss=1.38, lr=3.9e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.64it/s] 13.72it/s, loss=1.42, lr=3.43e-5]\n",
      "Epoch 8/10:  67%|██████▋   | 209/313 [00:27<01:00,  1.72it/s, loss=1.42, lr=3.43e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 125.89it/s] 13.76it/s, loss=1.52, lr=2.96e-5]\n",
      "Epoch 8/10:  99%|█████████▊| 309/313 [00:38<00:02,  1.72it/s, loss=1.52, lr=2.96e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 313/313 [00:38<00:00,  8.08it/s, loss=1.72, lr=2.94e-5]\n",
      "100%|██████████| 128/128 [00:01<00:00, 125.90it/s]13.76it/s, loss=1.66, lr=2.49e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 126.05it/s] 13.70it/s, loss=1.49, lr=2.02e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 126.03it/s] 13.76it/s, loss=1.38, lr=1.55e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 313/313 [00:34<00:00,  9.12it/s, loss=1.25, lr=1.47e-5]\n",
      "100%|██████████| 128/128 [00:01<00:00, 125.95it/s] 13.74it/s, loss=1.43, lr=1.08e-5]\n",
      "Epoch 10/10:  27%|██▋       | 83/313 [00:11<03:02,  1.26it/s, loss=1.43, lr=1.08e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 126.01it/s], 13.64it/s, loss=1.27, lr=6.1e-6] \n",
      "Epoch 10/10:  58%|█████▊    | 183/313 [00:22<01:15,  1.72it/s, loss=1.27, lr=6.1e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 126.05it/s], 13.72it/s, loss=1.46, lr=1.41e-6]\n",
      "Epoch 10/10:  90%|█████████ | 283/313 [00:33<00:17,  1.72it/s, loss=1.46, lr=1.41e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, True, True, True, True, True, True, True, True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 313/313 [00:35<00:00,  8.82it/s, loss=1.68, lr=0]      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Custom dataset for generating Sudoku boards\n",
    "class SudokuDataset(Dataset):\n",
    "    def __init__(self, num_samples=10000, board_size=9):\n",
    "        self.num_samples = num_samples\n",
    "        self.board_size = board_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # For now, we'll use a simple approach to generate valid Sudoku boards\n",
    "        # In a real implementation, you might want to use a more sophisticated generator\n",
    "        # completeness = int(torch.rand(1).item() * 100)\n",
    "        board = generate_board(completeness=100)\n",
    "        board = torch.tensor(board)\n",
    "        return board\n",
    "\n",
    "# Training function\n",
    "def train_diffusion_model(model, num_epochs=10, batch_size=32, lr=1e-4, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", eval_every_n_step=100, warmup_steps = 1000):\n",
    "    # Create dataset and dataloader\n",
    "    dataset = SudokuDataset()\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    \n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # warmp up lr scheduler\n",
    "    # Calculate total steps for the entire training\n",
    "    total_steps = len(dataloader) * num_epochs\n",
    "    \n",
    "    # Create a learning rate scheduler with linear warmup and linear decay\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            # Linear warmup phase\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        else:\n",
    "            # Linear decay phase\n",
    "            return max(0.0, float(total_steps - current_step) / float(max(1, total_steps - warmup_steps)))\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    total_step = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch_idx, boards in enumerate(progress_bar):\n",
    "            model.train()\n",
    "            boards = boards.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds_bld, loss = model.forward_loss(boards)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": loss.item(), \"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "            total_step += 1\n",
    "            if total_step % eval_every_n_step == 0:\n",
    "                model.eval()\n",
    "                # sample\n",
    "                with torch.no_grad():\n",
    "                    generated_boards = model.generate(batch_size=10)\n",
    "                    boards = generated_boards.chunk(generated_boards.shape[0], dim=0)\n",
    "                    boards = [b.squeeze(0).tolist() for b in boards]\n",
    "                    results = []\n",
    "                    board_figs = []\n",
    "                    for board in boards:\n",
    "                        results.append(verify_board(board))\n",
    "                        board_figs.append(visualize_sudoku(board))\n",
    "                    print(results)\n",
    "                    canvas_width = board_figs[0].width * len(boards)\n",
    "                    canvas_height = board_figs[0].height\n",
    "\n",
    "                    # create canvas\n",
    "                    canvas = Image.new(\"RGB\", (canvas_width, canvas_height), 'white')\n",
    "                    for i, board_fig in enumerate(board_figs):\n",
    "                        canvas.paste(board_fig, (board_fig.width * i, 0))\n",
    "                    canvas.save(f\"generated_boards_{total_step}.png\")\n",
    "                    canvas.close()\n",
    "                    \n",
    "                    # Clean up\n",
    "                    for fig in board_figs:\n",
    "                        fig.close()\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model = DiscreteDiffusion()\n",
    "trained_model = train_diffusion_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
