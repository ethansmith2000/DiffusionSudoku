{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sudoku_mrv import generate_board, verify_board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = generate_board(completeness=100, outer_grid_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 1, 5, 7, 9, 6, 2, 8, 3],\n",
       " [9, 6, 8, 1, 2, 3, 4, 5, 7],\n",
       " [7, 3, 2, 4, 5, 8, 1, 9, 6],\n",
       " [2, 5, 9, 3, 6, 1, 7, 4, 8],\n",
       " [1, 8, 3, 5, 4, 7, 6, 2, 9],\n",
       " [6, 7, 4, 2, 8, 9, 5, 3, 1],\n",
       " [8, 2, 1, 6, 3, 4, 9, 7, 5],\n",
       " [5, 9, 7, 8, 1, 2, 3, 6, 4],\n",
       " [3, 4, 6, 9, 7, 5, 8, 1, 2]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify_board(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import math \n",
    "# sampling helpers\n",
    "\n",
    "def log(t, eps = 1e-20):\n",
    "    return torch.log(t.clamp(min = eps))\n",
    "\n",
    "def gumbel_noise(t):\n",
    "    noise = torch.zeros_like(t).uniform_(0, 1)\n",
    "    return -log(-log(noise))\n",
    "\n",
    "def gumbel_sample(t, temperature = 1., dim = -1):\n",
    "    return ((t / max(temperature, 1e-10)) + gumbel_noise(t)).argmax(dim = dim)\n",
    "\n",
    "def top_k(logits, thres = 0.9):\n",
    "    k = math.ceil((1 - thres) * logits.shape[-1])\n",
    "    val, ind = logits.topk(k, dim = -1)\n",
    "    probs = torch.full_like(logits, float('-inf'))\n",
    "    probs.scatter_(2, ind, val)\n",
    "    return probs\n",
    "\n",
    "# noise schedules\n",
    "\n",
    "def cosine_schedule(t):\n",
    "    return torch.cos(t * math.pi * 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from PIL import Image\n",
    "import io\n",
    "from matplotlib import gridspec\n",
    "\n",
    "def visualize_sudoku(board, title=None, cmap=None, show_values=True, figsize=(6, 6), outer_grid_size=9):\n",
    "    \"\"\"\n",
    "    Visualize a Sudoku board with different colors for each number.\n",
    "    \n",
    "    Args:\n",
    "        board: A 9x9 numpy array or list of lists representing the Sudoku board\n",
    "        title: Optional title for the plot\n",
    "        cmap: Optional custom colormap (default is a pastel colormap)\n",
    "        show_values: Whether to display the numerical values in cells\n",
    "        figsize: Size of the figure (width, height) in inches\n",
    "        \n",
    "    Returns:\n",
    "        A PIL Image of the visualization\n",
    "    \"\"\"\n",
    "    # Create a new figure for each board to prevent any sharing\n",
    "    plt.clf()  # Clear the current figure\n",
    "    plt.close('all')  # Close all figures\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "\n",
    "    # Convert to numpy array if it's a list\n",
    "    if isinstance(board, list):\n",
    "        board = np.array(board)\n",
    "    \n",
    "    # Create a default colormap if none provided\n",
    "    if outer_grid_size == 9:\n",
    "        if cmap is None:\n",
    "            # Create a colormap with 10 colors (0-9, where 0 is empty)\n",
    "            colors = ['#FFFFFF',  # 0: White (empty)\n",
    "                    '#FFB3BA',  # 1: Light pink\n",
    "                    '#FFDFBA',  # 2: Light orange\n",
    "                    '#FFFFBA',  # 3: Light yellow\n",
    "                    '#BAFFC9',  # 4: Light green\n",
    "                    '#BAE1FF',  # 5: Light blue\n",
    "                    '#D0BAFF',  # 6: Light purple\n",
    "                    '#FFB3F6',  # 7: Light magenta\n",
    "                    '#C4C4C4',  # 8: Light gray\n",
    "                    '#FFD700']  # 9: Gold - changed from light cyan\n",
    "            cmap = ListedColormap(colors)\n",
    "    else:\n",
    "        # Create a colormap with colors from red to blue for numbers 0 to outer_grid_size\n",
    "        # White for 0 (empty cells)\n",
    "        colors = ['#FFFFFF']  \n",
    "        # Linear interpolation from red to blue for numbers 1 to outer_grid_size\n",
    "        for i in range(outer_grid_size):\n",
    "            r = int(255 * (outer_grid_size - i) / outer_grid_size)\n",
    "            b = int(255 * i / outer_grid_size)\n",
    "            colors.append(f'#{r:02x}00{b:02x}')\n",
    "        cmap = ListedColormap(colors)\n",
    "    \n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Plot the board\n",
    "    im = ax.imshow(board, cmap=cmap, vmin=0, vmax=outer_grid_size)\n",
    "\n",
    "    inner_grid_size = int(outer_grid_size ** 0.5)\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(outer_grid_size+1):\n",
    "        lw = 2 if i % inner_grid_size == 0 else 0.5\n",
    "        ax.axhline(i - 0.5, color='black', linewidth=lw)\n",
    "        ax.axvline(i - 0.5, color='black', linewidth=lw)\n",
    "    \n",
    "    # Add values to cells if requested\n",
    "    if show_values:\n",
    "        for i in range(outer_grid_size):\n",
    "            for j in range(outer_grid_size):\n",
    "                if board[i, j] != 0:\n",
    "                    ax.text(j, i, str(board[i, j]), ha='center', va='center', \n",
    "                            fontsize=12, fontweight='bold')\n",
    "    \n",
    "    # Remove ticks\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    # Add title if provided\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Convert to PIL image\n",
    "    pil_image = fig_to_pil(fig)\n",
    "    plt.close(fig)  # Close the figure to avoid displaying it\n",
    "    return pil_image\n",
    "\n",
    "def fig_to_pil(fig):\n",
    "    \"\"\"Convert a matplotlib figure to a PIL Image\"\"\"\n",
    "    buf = io.BytesIO()\n",
    "    fig.savefig(buf, format='png', bbox_inches='tight')\n",
    "    buf.seek(0)\n",
    "    img = Image.open(buf)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm \n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mult=4):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mult * 2), nn.GELU(), nn.Linear(dim * mult * 2, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x) + x\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, heads=8):\n",
    "        super().__init__()\n",
    "        self.heads = heads\n",
    "        self.to_qkv = nn.Linear(dim, dim * 3, bias=False)\n",
    "        self.to_out = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        q, k, v = map(lambda t: rearrange(t, \"b n (h d) -> b h n d\", h=self.heads), self.to_qkv(x).chunk(3, dim=-1))\n",
    "        attn_out = torch.nn.functional.scaled_dot_product_attention(q, k, v)\n",
    "        out = rearrange(attn_out, \"b h n d -> b n (h d)\", h=self.heads)\n",
    "        return self.to_out(out)\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, head_dim, heads=8):\n",
    "        super().__init__()\n",
    "        dim = head_dim * heads\n",
    "        self.attn = Attention(dim, heads)\n",
    "        self.ff = FeedForward(dim)\n",
    "        self.attn_norm = nn.LayerNorm(dim)\n",
    "        self.ff_norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.attn_norm(x))\n",
    "        x = x + self.ff(self.ff_norm(x))\n",
    "        return x\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, head_dim=64, heads=8, num_classes=10, depth=12, seq_len=81):\n",
    "        super().__init__()\n",
    "        dim = head_dim * heads\n",
    "        self.embed = nn.Embedding(num_classes, dim)\n",
    "        self.pos_emb = nn.Embedding(seq_len, dim)\n",
    "        self.layers = nn.ModuleList([TransformerBlock(head_dim, heads) for _ in range(depth)])\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.to_logits = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)\n",
    "        pos_idx = torch.arange(x.shape[1], device=x.device)\n",
    "        pos_embs = self.pos_emb(pos_idx)\n",
    "        x = x + pos_embs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        return self.to_logits(x)\n",
    "\n",
    "\n",
    "class DiscreteDiffusion(nn.Module):\n",
    "\n",
    "    def __init__(self, outer_grid_size=9, head_dim=64, heads=8, depth=12, full_mask_token_prob=0.025):\n",
    "        super().__init__()\n",
    "        num_classes = outer_grid_size + 1\n",
    "        self.outer_grid_size = outer_grid_size\n",
    "        self.model = Transformer(head_dim, heads, num_classes, depth, seq_len=outer_grid_size * outer_grid_size)\n",
    "        self.full_mask_token_prob = full_mask_token_prob\n",
    "\n",
    "    def forward(self, board_bl, labels=None):\n",
    "        \"\"\"\n",
    "        forward and compute loss\n",
    "        \"\"\"\n",
    "        preds_bld = self.model(board_bl)\n",
    "        if labels is not None:\n",
    "            loss = nn.functional.cross_entropy(preds_bld.reshape(-1, preds_bld.shape[-1]), labels.flatten(0), ignore_index=-1)\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        return preds_bld, loss\n",
    "\n",
    "    def forward_loss(self, board_bhw, ignore_index=-1):\n",
    "        mask_id = 0\n",
    "        b, h, w = board_bhw.shape\n",
    "        board_bl = board_bhw.flatten(1)\n",
    "        _, l = board_bl.shape\n",
    "\n",
    "        rand_time = torch.rand(board_bhw.shape[0], device=board_bl.device)\n",
    "        rand_mask_probs = cosine_schedule(rand_time)\n",
    "        num_token_masked = (l * rand_mask_probs).round().clamp(min = 1)\n",
    "\n",
    "        batch_randperm = torch.rand((b, l), device = board_bhw.device).argsort(dim = -1)\n",
    "        mask = batch_randperm < rearrange(num_token_masked, 'b -> b 1')\n",
    "\n",
    "        labels = torch.where(mask, board_bl, ignore_index)\n",
    "        \n",
    "        if self.full_mask_token_prob > 0.:\n",
    "            full_mask_mask = torch.full_like(mask, True)\n",
    "            indices = torch.arange(b, device=mask.device)\n",
    "            indices_mask = torch.bernoulli(torch.full((b,), self.full_mask_token_prob, device=mask.device)).long()\n",
    "            indices = indices[indices_mask]\n",
    "            mask[indices] = full_mask_mask[indices]\n",
    "\n",
    "        board_bl = torch.where(mask, mask_id, board_bl)\n",
    "        preds_bld, loss = self.forward(board_bl, labels=labels)\n",
    "\n",
    "        return preds_bld, loss\n",
    "\n",
    "    def generate(self, batch_size=32, timesteps=128, temperature=1.0, topk_filter_thres = 0.9, can_remask_prev_masked = False,):\n",
    "        device = next(self.parameters()).device\n",
    "        shape = (batch_size, self.outer_grid_size, self.outer_grid_size)\n",
    "        board_bhw = torch.full(shape, 0, dtype=torch.long, device=device)\n",
    "        scores_bhw = torch.zeros(shape, dtype = torch.float32, device = device)\n",
    "        board_bl = board_bhw.flatten(1)\n",
    "        scores_bl = scores_bhw.flatten(1)\n",
    "        seq_len = board_bl.shape[1]\n",
    "\n",
    "        starting_temperature = temperature\n",
    "        mask_id = 0\n",
    "\n",
    "        for timestep, steps_until_x0 in tqdm(zip(torch.linspace(0, 1, timesteps, device = device), reversed(range(timesteps))), total = timesteps):\n",
    "            rand_mask_prob = cosine_schedule(timestep)\n",
    "            num_token_masked = max(int((rand_mask_prob * seq_len).item()), 1)\n",
    "\n",
    "            masked_indices = scores_bl.topk(num_token_masked, dim = -1).indices\n",
    "\n",
    "            board_bl = board_bl.scatter(1, masked_indices, mask_id)\n",
    "\n",
    "            logits, _ = self.forward(board_bl)\n",
    "\n",
    "            filtered_logits = top_k(logits, topk_filter_thres)\n",
    "\n",
    "            temperature = starting_temperature * (steps_until_x0 / timesteps) # temperature is annealed\n",
    "\n",
    "            pred_ids = gumbel_sample(filtered_logits, temperature = temperature, dim = -1)\n",
    "\n",
    "            is_mask = board_bl == mask_id\n",
    "\n",
    "            board_bl = torch.where(\n",
    "                is_mask,\n",
    "                pred_ids,\n",
    "                board_bl\n",
    "            )\n",
    "\n",
    "            probs_without_temperature = logits.softmax(dim = -1)\n",
    "\n",
    "            scores_bl = 1 - probs_without_temperature.gather(2, pred_ids[..., None])\n",
    "            scores_bl = rearrange(scores_bl, '... 1 -> ...')\n",
    "\n",
    "            if not can_remask_prev_masked:\n",
    "                scores_bl = scores_bl.masked_fill(~is_mask, -1e5)\n",
    "            else:\n",
    "                assert self.no_mask_token_prob > 0., 'without training with some of the non-masked tokens forced to predict, not sure if the logits will be meaningful for these token'\n",
    "\n",
    "        board_bhw = board_bl.reshape(board_bhw.shape)\n",
    "\n",
    "        return board_bhw\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:01<00:00, 116.96it/s]13.67it/s, loss=2.2, lr=5e-5]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, False, False, False, False, False, False, False, False, False]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  42%|████▏     | 131/313 [00:14<00:13, 13.08it/s, loss=2.2, lr=6.55e-5]"
     ]
    }
   ],
   "source": [
    "# trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "# Custom dataset for generating Sudoku boards\n",
    "class SudokuDataset(Dataset):\n",
    "    def __init__(self, num_samples=10000, board_size=9):\n",
    "        self.num_samples = num_samples\n",
    "        self.board_size = board_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # For now, we'll use a simple approach to generate valid Sudoku boards\n",
    "        # In a real implementation, you might want to use a more sophisticated generator\n",
    "        # completeness = int(torch.rand(1).item() * 100)\n",
    "        board = generate_board(completeness=100, outer_grid_size=self.board_size)\n",
    "        board = torch.tensor(board)\n",
    "        return board\n",
    "\n",
    "# Training function\n",
    "def train_diffusion_model(model, outer_grid_size=9, num_epochs=10, batch_size=32, lr=1e-4, device=\"cuda\" if torch.cuda.is_available() else \"cpu\", eval_every_n_step=100, warmup_steps = 200, compiled=False):\n",
    "    # Create dataset and dataloader\n",
    "    dataset = SudokuDataset(board_size=outer_grid_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "    \n",
    "    # Setup optimizer\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, betas=(0.9, 0.997), weight_decay=0.01)\n",
    "    \n",
    "    # warmp up lr scheduler\n",
    "    # Calculate total steps for the entire training\n",
    "    total_steps = len(dataloader) * num_epochs\n",
    "    \n",
    "    # Create a learning rate scheduler with linear warmup and linear decay\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            # Linear warmup phase\n",
    "            return float(current_step) / float(max(1, warmup_steps))\n",
    "        else:\n",
    "            # Linear decay phase\n",
    "            return max(0.0, float(total_steps - current_step) / float(max(1, total_steps - warmup_steps)))\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    if compiled:\n",
    "        model = torch.compile(model)\n",
    "\n",
    "    total_step = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for batch_idx, boards in enumerate(progress_bar):\n",
    "            model.train()\n",
    "            boards = boards.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            preds_bld, loss = model.forward_loss(boards)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": loss.item(), \"lr\": optimizer.param_groups[0]['lr']})\n",
    "\n",
    "            total_step += 1\n",
    "            if total_step % eval_every_n_step == 0:\n",
    "                model.eval()\n",
    "                # sample\n",
    "                with torch.no_grad():\n",
    "                    generated_boards = model.generate(batch_size=10)\n",
    "                    boards = generated_boards.chunk(generated_boards.shape[0], dim=0)\n",
    "                    boards = [b.squeeze(0).tolist() for b in boards]\n",
    "                    results = []\n",
    "                    board_figs = []\n",
    "                    for board in boards:\n",
    "                        results.append(verify_board(board, outer_grid_size=model.outer_grid_size))\n",
    "                        board_figs.append(visualize_sudoku(board, outer_grid_size=model.outer_grid_size))\n",
    "                    print(results)\n",
    "                    canvas_width = board_figs[0].width * len(boards)\n",
    "                    canvas_height = board_figs[0].height\n",
    "\n",
    "                    # create canvas\n",
    "                    canvas = Image.new(\"RGB\", (canvas_width, canvas_height), 'white')\n",
    "                    for i, board_fig in enumerate(board_figs):\n",
    "                        canvas.paste(board_fig, (board_fig.width * i, 0))\n",
    "                    canvas.save(f\"generated_boards_{total_step}.png\")\n",
    "                    canvas.close()\n",
    "                    \n",
    "                    # Clean up\n",
    "                    for fig in board_figs:\n",
    "                        fig.close()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "outer_grid_size = 9\n",
    "model = DiscreteDiffusion(outer_grid_size=outer_grid_size)\n",
    "trained_model = train_diffusion_model(model, outer_grid_size=outer_grid_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
